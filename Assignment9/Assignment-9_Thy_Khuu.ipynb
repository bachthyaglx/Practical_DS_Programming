{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment 9\n",
    "\n",
    "In this assigment you will implement\n",
    "\n",
    " * the precision score\n",
    " * a text classifier for german parliament speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assignment 01\n",
    "\n",
    "Implement a function assignment_01 that computes the precision of binary predictions:\n",
    "\n",
    "$${\\text{precision}}={\\frac {|\\{{\\text{relevant instances}}\\}\\cap \\{{\\text{predicted instances}}\\}|}{|\\{{\\text{predicted instances}}\\}|}}$$\n",
    "\n",
    "\n",
    "The function should expect the true and predicted binary categories as numpy vectors, meaning numpy arrays with only one axis as e.g. ``np.array([1,0])`` where 1 stands for positive prediction and 0 for negative prediction. Make sure that always a number is returned and not a NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def assignment_01(y_true, y_predicted):\n",
    "    # INSERT CODE\n",
    "    y_true = np.array(y_true)\n",
    "    y_predicted = np.array(y_predicted)\n",
    "    \n",
    "    # Ensure that both arrays have the same shape\n",
    "    if y_true.shape != y_predicted.shape:\n",
    "        raise ValueError(\"Input arrays must have the same shape.\")\n",
    "    \n",
    "    # Calculate the intersection of relevant and predicted instances\n",
    "    intersection = np.sum((y_true == 1) & (y_predicted == 1))\n",
    "    \n",
    "    # Calculate the number of predicted instances\n",
    "    num_predicted = np.sum(y_predicted == 1)\n",
    "    \n",
    "    # Calculate precision, handle the case when num_predicted is 0\n",
    "    precision = intersection / num_predicted if num_predicted != 0 else 0\n",
    "    \n",
    "    # Ensure that the result is a number and not NaN\n",
    "    return float(precision)\n",
    "\n",
    "assert assignment_01(np.array([1,1,0]),np.array([0,0,0])) == 0\n",
    "assert assignment_01(np.array([1,1,0]),np.array([1,1,0])) == 1\n",
    "assert assignment_01(np.array([1,1,0]),np.array([1,0,0])) == 1\n",
    "assert assignment_01(np.array([1,1,0]),np.array([0,1,1])) == .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assignment 02\n",
    "\n",
    "In the 17th Bundestag elected in 2009, the ruling parties were CDU/CSU and FDP, in the 18th Bundestag elected in 2013 the ruling parties were CDU/CSU and SPD. Download the [parliament speeches](https://www.dropbox.com/s/1nlbfehnrwwa2zj/bundestags_parlamentsprotokolle.csv.gzip?dl=1) and compute a new target variable 'government' that is true if the respective party was in the ruling coalition at the time. \n",
    "\n",
    "Write a function ``assignment_02`` that preprocesses the data and trains a text classification pipeline that predicts whether a speech was made by the governing party. Train the pipeline on the speeches of the 17th Bundestag and test them on (heldout) data from the 17th Bundestag as well as on data from the 18th Bundestag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Evaluation on 17th Bundestag held-out data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.87      0.86      3190\n",
      "        True       0.84      0.82      0.83      2722\n",
      "\n",
      "    accuracy                           0.84      5912\n",
      "   macro avg       0.84      0.84      0.84      5912\n",
      "weighted avg       0.84      0.84      0.84      5912\n",
      "\n",
      "********************************************************************************\n",
      "Evaluation on 18th Bundestag held-out data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.91      0.70      6009\n",
      "        True       0.95      0.70      0.81     14025\n",
      "\n",
      "    accuracy                           0.76     20034\n",
      "   macro avg       0.76      0.80      0.75     20034\n",
      "weighted avg       0.83      0.76      0.77     20034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import urllib.request\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "DATADIR = \"data\"\n",
    "\n",
    "def load_data():\n",
    "    if not os.path.exists(DATADIR): \n",
    "        os.mkdir(DATADIR)\n",
    "\n",
    "    file_name = os.path.join(DATADIR, 'bundestags_parlamentsprotokolle.csv.gzip')\n",
    "    if not os.path.exists(file_name):\n",
    "        url_data = 'https://www.dropbox.com/s/1nlbfehnrwwa2zj/bundestags_parlamentsprotokolle.csv.gzip?dl=1'\n",
    "        urllib.request.urlretrieve(url_data, file_name)\n",
    "\n",
    "    df = pd.read_csv(gzip.open(file_name), index_col=0).sample(frac=1)\n",
    "    df.loc[df.wahlperiode==17,'government'] = df[df.wahlperiode==17].partei.isin(['cducsu','fdp']).astype(str)\n",
    "    df.loc[df.wahlperiode==18,'government'] = df[df.wahlperiode==18].partei.isin(['cducsu','spd']).astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def assignment_02():\n",
    "    df = load_data()\n",
    "    \n",
    "    # Put some data aside for model evaluation\n",
    "    X, y = df.loc[df.wahlperiode==17,'text'], df.loc[df.wahlperiode==17,'government']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=5912)\n",
    "    \n",
    "    # Create a pipeline with a TfidfVectorizer and SGDClassifier\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('clf', SGDClassifier())\n",
    "    ])\n",
    "    \n",
    "    # Hyperparameters for grid search\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'clf__alpha': (np.logspace(-5, 2, 5)).tolist()\n",
    "    }\n",
    "    \n",
    "    # Perform grid search to find the best hyperparameters\n",
    "    clf = GridSearchCV(text_clf, parameters, cv=2, n_jobs=-1,verbose=0)\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"*\"*80 + \"\\nEvaluation on 17th Bundestag held-out data\")\n",
    "    print(classification_report(y_test, clf.predict(X_test)))\n",
    "\n",
    "    predictions = clf.predict(df.loc[df.wahlperiode==18,'text'])\n",
    "    print(\"*\"*80 + \"\\nEvaluation on 18th Bundestag held-out data\")\n",
    "    print(classification_report(df.loc[df.wahlperiode==18,'government'], predictions))\n",
    "\n",
    "assignment_02()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
